\section{Projection and separation}

\begin{exercise}
  Give an example where the nearest point is unique, and one where it is not.
  Find a point $x$ and a set $S$ such that every point of $S$ is a nearest point to $x$!
\end{exercise}

\begin{solution}
  Consider first the singleton set $S = \{ 1 \} \subset \mathbb{R}$.
  Then, for any point $x \in \mathbb{R}$, the nearest point in $S$ to $x$ is simply $1$, which is unique.
  Now, consider the set $S = \{ -1, 1 \} \subset \mathbb{R}$.
  If we take $x = 0$, then both $-1$ and $1$ are nearest points to $x$, and thus the nearest point is not unique, and additionally every point in $S$ is a nearest point to $x$.
\end{solution}

\begin{exercise}
  Let $a \in \mathbb{R}^n \setminus \{0\}$ and $x_0 \in \mathbb{R}^n$.
  Then there is a unique hyperplane $H$ that contains $x_0$ and has a normal vector $a$.
  Verify this and find the value of the constant $\alpha$ in the definition of $H = \{ x \in \mathbb{R}^n : a^T x = \alpha \}$.
\end{exercise}

\begin{solution}
  The hyperplane $H$ is defined by $a^T x = a^T x_0$.
  Thus, the constant $\alpha$ is given by $\alpha = a^T x_0$.
  To see that this hyperplane is unique, suppose there is another hyperplane $H'$ with the same normal vector $a$ that also contains $x_0$.
  Then $H'$ must be defined by $a^T x = \beta$ for some constant $\beta$.
  Since $x_0 \in H'$, we have $a^T x_0 = \beta$.
  But we already have $a^T x_0 = \alpha$, so $\beta = \alpha$.
  Therefore, $H' = H$, proving the uniqueness of the hyperplane.
\end{solution}

\begin{exercise}
  Give an example of two disjoint sets $S$ and $T$ that cannot be separated by a hyperplane.
\end{exercise}

\begin{solution}
  Consider the sets $S = \{ x \in \mathbb{R}^2 : \norm{x}_2 < r \}$ and $T = \{ x \in \mathbb{R}^2 : r < \norm{x}_2 < 2r \}$ for some $r > 0$.
  These sets are disjoint, as there are no points that belong to both $S$ and $T$.
  However, they cannot be separated by a hyperplane, as there is no linear boundary that can separate the inner circle $S$ from the annular region $T$ without intersecting either set.
\end{solution}

\begin{exercise}
  In view of the previous remark, what about the separation of $S$ and a point $p \notin \aff(S)$?
  Is there an easy way to find a separating hyperplane?
\end{exercise}

\begin{solution}

\end{solution}

\begin{exercise}
  Let $C \subseteq \mathbb{R}^n$ be convex.
  Recall that if a point $x_0 \in C$ satisfies~\eqref{eq:unique_nearest} for any $y \in C$, then $x_0$ is the (unique) nearest point to $x$ in $C$.
  Now, let $C$ be the unit ball in $\mathbb{R}^n$ and let $x \in \mathbb{R}^n$ satisfy $\norm{x} > 1$.
  Find the nearest point to $x$ in $C$.
  What if $\norm{x} \leq 1$?
\end{exercise}

\begin{solution}
  \eqref{eq:unique_nearest} states % chktex 2
  \begin{equation}\label{eq:unique_nearest}
    (x - x_0)^T (y - x_0) \leq 0 \quad \text{for all } y \in C. \tag{3.2}
  \end{equation}
  When $\norm{x} > 1$, we have that $x \notin C$.
  The nearest point to $x$ in $C$ is given by
  \begin{equation}
    x_0 = \frac{x}{\norm{x}}.
  \end{equation}
  Plugging this into~\eqref{eq:unique_nearest}, we have for $\norm{x} > 1$ and any $y \in C$ that
  \begin{equation}
    \begin{split}
      (x - x_0)^T (y - x_0) &= \left(x - \frac{x}{\norm{x}}\right)^T \left(y - \frac{x}{\norm{x}}\right) \\
      &= \left(1 - \frac{1}{\norm{x}}\right) x^T \left(y - \frac{x}{\norm{x}}\right) \\
      &\leq x^T y - \frac{x^T x}{\norm{x}}
      = x^T y - \norm{x} \\
      &\leq \norm{x} \norm{y} - \norm{x} \\
      &\leq \norm{x} - \norm{x}
      = 0.
    \end{split}
  \end{equation}
  Therefore, $x_0$ is indeed the nearest point to $x$ in $C$ when $\norm{x} > 1$.

  For $\norm{x} \leq 1$, we have that $x \in C$, and thus the nearest point to $x$ in $C$ is simply $x$ itself.
\end{solution}

\begin{exercise}
  Let $L$ be a line in $\mathbb{R}^n$.
  Find the nearest point in $L$ to a point $x \in \mathbb{R}^n$.
  Use your result to find the nearest point on the line $L = \{ (x, y) : x + 3y = 5 \}$ to the point $(1, 2)$.
\end{exercise}

\begin{solution}
  Let $L$ be the defined by the line $\{ b + t d : t \in \mathbb{R} \}$, where $b$ is a point on the line and $d$ is a direction vector.
  The nearest point on $L$ to a point $x \in \mathbb{R}^n$ can be found by projecting the vector $x - b$ onto the direction vector $d$.
  The projection is given by
  \begin{equation}
    \mathrm{proj}_d (x - b) = b + \frac{(x - b)^T d}{\norm{d}^2} d.
  \end{equation}

  With $b = (5, 0)$, we note that $(1, 3)$ is orthogonal to the line, so we choose the direction vector to be $d = (-3, 1)$.
  Then, the nearest point on the line $L$ to the point $(1, 2)$ is given by
  \begin{equation}
    \begin{split}
      \mathrm{proj}_d ((1, 2) - (5, 0)) &= \mathrm{proj}_d ((-4, 2))
      = (5, 0) + \frac{(-4, 2)^T (-3, 1)}{\norm{(-3, 1)}^2} (-3, 1) \\
      &= (5, 0) + \frac{14}{10} (-3, 1)
      =\left(\frac{25}{5}, 0\right) + \left(-\frac{21}{5}, \frac{7}{5}\right) \\
      &= \left(\frac{4}{5}, \frac{7}{5}\right).
    \end{split}
  \end{equation}
  Therefore, the nearest point on the line $L$ to the point $(1, 2)$ is $\left(\frac{4}{5}, \frac{7}{5}\right)$.
\end{solution}

\begin{exercise}
  Let $H$ be a hyperplane in $\mathbb{R}^n$.
  Find the nearest point in $H$ to a point $x \in \mathbb{R}^n$.
  In particular, find the nearest point to each of the point $(0,0,0)$ and $(1,2,2)$ in the hyperplane $H = \{ (x_1, x_2, x_3) : x_1 + x_2 + x_3 = 1 \}$.
\end{exercise}

\begin{solution}
  The hyperplane $H$ can be defined by the equation $a^T x = \alpha$, where $a$ is the normal vector to the hyperplane and $\alpha$ is a constant.
  As we can write a hyperplane on the form $H = x_0 + L$ for some point $x_0 \in H$.
  Similarly as before, we can find the nearest point on $H$ to a point $x \in \mathbb{R}^n$ by projecting the vector $x - x_0$ onto the normal vector $a$.
  This gives us
  \begin{equation}
    \mathrm{proj}_H (x) = (x - x_0) - \frac{(x - x_0)^T a}{\norm{a}^2} a + x_0 = x - \frac{x^T a - \alpha}{\norm{a}^2} a,
  \end{equation}
  where the chosen point $x_0 \in H$ is arbitrary, as we can utilize the property $x_0^T a = \alpha$.
  For the hyperplane $H = \{ (x_1, x_2, x_3) : x_1 + x_2 + x_3 = 1 \}$, we can choose the normal vector $a = (1, 1, 1)$.
  Then, the nearest point on $H$ to the point $(0, 0, 0)$ is given by
  \begin{equation}
    \begin{split}
      \mathrm{proj}_H ((0, 0, 0)) &= (0, 0, 0) - \frac{(0, 0, 0)^T (1, 1, 1) - 1}{\norm{(1, 1, 1)}^2} (1, 1, 1) \\
      &= (0, 0, 0) - \frac{-1}{3} (1, 1, 1) \\
      &= \left(\frac{1}{3}, \frac{1}{3}, \frac{1}{3}\right).
    \end{split}
  \end{equation}
  For the point $x = (1, 2, 2)$, we have $x^T a = 5$, so the nearest point is given by
  \begin{equation}
    \mathrm{proj}_H (x) = x - \frac{5 - 1}{3} a = (1, 2, 2) - \frac{4}{3} (1, 1, 1) = \left(-\frac{1}{3}, \frac{2}{3}, \frac{2}{3}\right).
  \end{equation}
\end{solution}

\begin{exercise}
  Let $L$ be a linear subspace in $\mathbb{R}^n$ and let $q_1, \ldots, q_t$ be an orthonormal basis for $L$.
  Thus $q_1, \ldots, q_t$ span $L$, and $q_i^T q_j = \delta_{ij}$.
  Let $Q$ be the $(n \times t)$-matrix whose $j$-th column is $q_j$.
  Define the associated matrix $P = Q Q^T$.
  Show that $Px$ is the nearest point in $L$ to $x$.
  (The matrix $P$ is called an orthogonal projector (or projection matrix)).
  Thus, performing the projection is simply to apply the linear transformation given by $P$.
  Let $L^\perp$ be the orthogonal complement of $L$.
  Explain why $(I - P)x$ is the nearest point in $L^\perp$ to $x$.
\end{exercise}

\begin{solution}
  Note firstly that we have $Q^T Q = I_t$, such that we have $P^2 = Q Q^T Q Q^T = Q I_t Q^T = P$, and thus $P$ is indeed a projection matrix.
  Consider then the point $b = Px$.
  We have
  \begin{equation}
    b = Px = P^2 x = P (Px) = P b.
  \end{equation}
  Note next that for a vector $y \in L$, we have $y = Q z$ for some $z \in \mathbb{R}^t$.
  Then,
  \begin{equation}
    (x - b)^T (y - b) = (x - Px)^T (Q z - Px) = x^T Q z - x^T P x - x^T P Q z + x^T P^2 x.
  \end{equation}
  Using the properties of $P$, we have $P Q = Q$ and $P^2 = P$, such that
  \begin{equation}
    (x - b)^T (y - b) = x^T Q z - x^T P x - x^T Q z + x^T P x = 0.
  \end{equation}
  Thus, $b = Px$ satisfies~\eqref{eq:unique_nearest}, and is therefore the nearest point in $L$ to $x$.

  For the orthogonal complement $L^\perp$, we have that any vector $w \in L^\perp$ satisfies $w^T v = 0$ for all $v \in L$.
  Note that for any $x \in \mathbb{R}^n$, we can decompose $x$ as $x = Px + (I - P)x$, where $Px \in L$.
  We have that $(I - P)x \in L^\perp$, since for any $v \in L$, we have
  \begin{equation}
    ((I - P)x)^T v = x^T (I - P)^T v = x^T (I - P) v = x^T (v - Pv) = x^T (v - v) = 0.
  \end{equation}
  Thus, $(I - P)x$ is orthogonal to every vector in $L$, and is therefore the nearest point in $L^\perp$ to $x$, as
  \begin{equation}
    \begin{split}
      (x - (I - P)x)^T (w - (I - P)x) &= (Px)^T (w - (I - P)x) \\
      &= (Px)^T w - x^T P (I - P)x \\
      &= 0 - x^T (P - P)x \\
      &= 0
    \end{split}
  \end{equation}
  for any $w \in L^\perp$, as $Px \in L$.
\end{solution}

\begin{exercise}
  Let $L \subset \mathbb{R}^3$ be a subspace spanned by the vectors $(1, 0, 1)$ and $(0, 1, 0)$.
  Find the nearest point to $(1, 2, 3)$ in $L$ using the results of the previous exercise.
\end{exercise}

\begin{solution}
  We then have
  \begin{equation}
    Q =
    \begin{bmatrix}
      \frac{1}{\sqrt{2}} & 0 \\
      0 & 1 \\
      \frac{1}{\sqrt{2}} & 0
    \end{bmatrix},
  \end{equation}
  such that $P$ is given by
  \begin{equation}
    P = Q Q^T =
    \begin{bmatrix}
      \frac{1}{\sqrt{2}} & 0 \\
      0 & 1 \\
      \frac{1}{\sqrt{2}} & 0
    \end{bmatrix}
    \begin{bmatrix}
      \frac{1}{\sqrt{2}} & 0 & \frac{1}{\sqrt{2}} \\
      0 & 1 & 0
    \end{bmatrix} =
    \begin{bmatrix}
      \frac{1}{2} & 0 & \frac{1}{2} \\
      0 & 1 & 0 \\
      \frac{1}{2} & 0 & \frac{1}{2}
    \end{bmatrix}.
  \end{equation}
  The nearest point to $(1, 2, 3)$ in $L$ is then given by
  \begin{equation}
    P x =
    \begin{bmatrix}
      \frac{1}{2} & 0 & \frac{1}{2} \\
      0 & 1 & 0 \\
      \frac{1}{2} & 0 & \frac{1}{2}
    \end{bmatrix}
    \begin{bmatrix}
      1 \\
      2 \\
      3
    \end{bmatrix} =
    \begin{bmatrix}
      2 \\
      2 \\
      2
    \end{bmatrix}.
  \end{equation}
  Note: There is a mistake in the suggested solutions, as they haven't normalized the basis vectors.
\end{solution}

\begin{exercise}
  Show that the nearest point in $\mathbb{R}^n_+$ to $x \in \mathbb{R}^n$ is the point $x^+$ defined by $x^+_i = \max(x_i, 0)$.
\end{exercise}

\begin{solution}
  Let $C = \mathbb{R}^n_+$ and consider the point $x^+$ defined by $x^+_i = \max(x_i, 0)$.
  We want to show that $x^+$ is the nearest point in $C$ to $x$ by verifying~\eqref{eq:unique_nearest}.
  For any $y \in C$, we have
  \begin{equation}
    (x - x^+)^T (y - x^+) = \sum_{i=1}^n (x_i - x^+_i)(y_i - x^+_i).
  \end{equation}
  Note that if $x_i \geq 0$, then $x^+_i = x_i$, and thus the term $(x_i - x^+_i)(y_i - x^+_i) = 0$.
  If $x_i < 0$, then $x^+_i = 0$, and since $y_i \geq 0$ (as $y \in C$), we have $(x_i - x^+_i)(y_i - x^+_i) = x_i y_i \leq 0$.
  Therefore, each term in the sum is non-positive, and we conclude that
  \begin{equation}
    (x - x^+)^T (y - x^+) \leq 0,
  \end{equation}
  for all $y \in C$.
  Thus, by~\eqref{eq:unique_nearest}, $x^+$ is indeed the nearest point in $\mathbb{R}^n_+$ to $x$.
\end{solution}

\begin{exercise}
  Find a set $S \subset \mathbb{R}^n$ and a point $x \in \mathbb{R}^n$ with the property that every point of $S$ is nearest to $x$ in $S$!
\end{exercise}

\begin{solution}
  Let $S = \{ y \in \mathbb{R}^n : \norm{y} = r \}$ for some fixed $r > 0$, which is the surface of a sphere centred at the origin.
  Let $x = 0 \in \mathbb{R}^n$.
  Then, for any point $y \in S$, we have $\norm{x - y} = \norm{y} = r$.
  Since all points in $S$ are at the same distance $r$ from $x$, every point of $S$ is a nearest point to $x$ in $S$.
\end{solution}

\setexsol{13}

\begin{exercise}
  Let $C = [0,1] \times [0,1] \subset \mathbb{R}^2$ and let $y = (2,2)$.
  Find \emph{all} hyperplanes that separates $C$ and $y$.
\end{exercise}

\begin{solution}
  Let $H = \{ x \in \mathbb{R}^2 : a^T x = \alpha \}$ be a hyperplane that separates $C$ and $y$.
  Then, we must have either
  \begin{equation}
    \sup_{x \in C} a^T x < a^T y
    \quad\text{or}\quad
    \inf_{x \in C} a^T x > a^T y.
  \end{equation}
  We have $\sup_{x \in C} a^T x = \max(a_1, 0) + \max(a_2, 0)$ and $\inf_{x \in C} a^T x = \min(a_1, 0) + \min(a_2, 0)$.
  Thus, the first condition becomes
  \begin{equation}
    \max(a_1, 0) + \max(a_2, 0) < 2 (a_1 + a_2),
  \end{equation}
  and the second condition becomes
  \begin{equation}
    \min(a_1, 0) + \min(a_2, 0) > 2 (a_1 + a_2).
  \end{equation}
\end{solution}