\section{The basic concepts}

\begin{exercise}
  Let \( x_1, x_2, y_1, y_2 \in \mathbb{R}^n \) and assume that $x_1 \leq x_2$ and $y_1 \leq y_2$.
  Verify that the inequality $x_1 + y_1 \leq x_2 + y_2$ holds.
  Let now $\lambda$ be a non-negative real number.
  Explain why $\lambda x_1 \leq \lambda x_2$ holds.
  What happens if $\lambda$ is negative?
\end{exercise}

\begin{solution}
  With $x_1 \leq x_2$, we have that
  \begin{equation}
    (x_1)_i \leq (x_2)_i \qquad \forall i = 1, \ldots, n.
  \end{equation}
  Component-wise, we then have
  \begin{equation}
    (x_1)_i + (y_1)_i \leq (x_2)_i + (y_2)_i \qquad \forall i = 1, \ldots, n,
  \end{equation}
  and thus $x_1 + y_1 \leq x_2 + y_2$.
  Similarly, if $\lambda \geq 0$, we have
  \begin{equation}
    \lambda (x_1)_i \leq \lambda (x_2)_i \qquad \forall i = 1, \ldots, n,
  \end{equation}
  and therefore $\lambda x_1 \leq \lambda x_2$.
  Finally, for $\lambda < 0$, the inequality reverses:
  \begin{equation}
    \lambda (x_1)_i \geq \lambda (x_2)_i \qquad \forall i = 1, \ldots, n,
  \end{equation}
  giving $\lambda x_1 \geq \lambda x_2$.
\end{solution}

\paragraph{Example 1.2.1}
\emph{(The non-negative real vectors)}
The sum of two non-negative numbers is again a non-negative number.
Similarly, we see that the sum of two non-negative vectors is a non-negative vector.
Moreover, if we multiply a non-negative vector by a non-negative number, we get another non-negative vector.
These two properties may be summarized by saying that $\mathbb{R}^n_+$ is closed under addition and multiplication by non-negative scalars.
We shall see that this means that $\mathbb{R}^n_+$ is a convex cone, a special type of convex set.

\begin{exercise}
  Think about the question in Exercise 1.1 again, now in light of the properties explained in Example 1.2.1.
\end{exercise}

\begin{solution}
  We can now rewrite $x_1 \leq x_2$ as $x_2 - x_1 \in \mathbb{R}^n_+$.
  We can now easily consider the first question as
  \begin{equation}
    (x_2 + y_2) - (x_1 + y_1) = (x_2 - x_1) + (y_2 - y_1) \in \mathbb{R}^n_+,
  \end{equation}
  as $\mathbb{R}^n_+$ is closed under addition.
  Similarly, we can use the fact that $\mathbb{R}^n_+$ is closed under multiplication by non-negative scalars to see that
  \begin{equation}
    (\lambda x_2 - \lambda x_1) = \lambda (x_2 - x_1) \in \mathbb{R}^n_+,
  \end{equation}
  for $\lambda \geq 0$.
  As $\mathbb{R}^n_+$ is not closed under multiplication by negative scalars, we cannot conclude that $\lambda x_1 \leq \lambda x_2$ for $\lambda < 0$.
\end{solution}

\begin{exercise}
  Let $a \in \mathbb{R}^n_+$ and assume that $x \leq y$.
  Show that $a^T x \leq a^T y$.
  What happens if we do not require $a$ to be non-negative here?
\end{exercise}

\begin{solution}
  With $a \in \mathbb{R}^n_+$ and $x \leq y$, we have that
  \begin{equation}
    x_i \leq y_i \qquad \forall i = 1, \ldots, n,
  \end{equation}
  and consequently
  \begin{equation}
    a_i x_i \leq a_i y_i \qquad \forall i = 1, \ldots, n,
  \end{equation}
  as shown previously.
  Written in vector notation, we therefore have
  \begin{equation}
    a^T x \leq a^T y.
  \end{equation}
  With $a$ not necessarily non-negative, we may have neither $a^T x \geq a^T y$ nor $a^T x \leq a^T y$, as we could have $a_i x_i > a_i y_i$ for some $i$.
\end{solution}

\begin{exercise}
  Show that every ball $B(a, r): = \{ x \in \mathbb{R}^n : \norm{x - a} \leq r \}$ is convex (where $a \in \mathbb{R}^n$ and $r \geq 0$).
\end{exercise}

\begin{solution}
  Let $x, y \in B(a, r)$ for some $a \in \mathbb{R}^n$ and $r \geq 0$.
  Then, let $0 \leq \lambda \leq 1$ and consider $z = \lambda x + (1 - \lambda) y$.
  We then have
  \begin{equation}
    \begin{split}
      \norm{z - a} &= \norm{\lambda (x - a) + (1 - \lambda) (y - a)} \\
      &\leq \lambda \norm{x - a} + (1 - \lambda) \norm{y - a} \\
      &\leq \lambda r + (1 - \lambda) r = r,
    \end{split}
  \end{equation}
  showing that $z \in B(a, r)$.
  $B(a, r)$ is therefore convex.
\end{solution}

\begin{exercise}
  Explain how you can write the LP problem $\max\{ c^T x : Ax \leq b \}$ in the form $\max\{ c^T x : Ax = b, x \geq O \}$
\end{exercise}

\begin{solution}
  We introduce new slack variables $w \in \mathbb{R}^m_+$, where $m$ is the number of rows/inequalities in $A$, defined by
  \begin{equation}
    w_j = b_j - (Ax)_j \quad \forall j = 1, \ldots, m.
  \end{equation}
  We can then rewrite our system of equations by setting $\tilde{A} =
  \begin{bmatrix} A & I
  \end{bmatrix}$, $\tilde{x} =
  \begin{bmatrix} x \\ w
  \end{bmatrix}$, and $\tilde{c} =
  \begin{bmatrix} c \\ 0
  \end{bmatrix}$.
  We then have
  \begin{equation}
    \tilde{A} \tilde{x} =
    \begin{bmatrix} A & I
    \end{bmatrix}
    \begin{bmatrix} x \\ w
    \end{bmatrix} = Ax + w = b,
  \end{equation}
  and
  \begin{equation}
    \tilde{c}^T \tilde{x} =
    \begin{bmatrix} c \\ 0
    \end{bmatrix}^T
    \begin{bmatrix} x \\ w
    \end{bmatrix} = c^T x.
  \end{equation}
  Again, as we require $w \geq 0$, we then have $Ax \leq b$.
\end{solution}

\begin{exercise}
  Make a drawing of the standard simplices $S_1$, $S_2$, and $S_3$.
  Verify that each unit vector $e_j$ lies in $S_n$ ($e_j$ has a one in position $j$, all other components are zero).
  Each $x \in S_n$ may be written as a linear combination $x = \sum_{j=1}^{n} \lambda_j e_j$ where each $\lambda_j$ is non-negative and $\sum_{j = 1}^{n} \lambda_j = 1$.
  How?
  Can this be done in several ways?
\end{exercise}

\begin{solution}

  \cref{fig:simplices} shows the standard simplices $S_1$, $S_2$, and $S_3$.
  Clearly each unit vector $e_j$ lies in $S_n$.
  Each $x \in S_n$ may be written as $\sum_{j=1}^{n} \lambda_j e_j$ where $\lambda_j = x_j$, i.e.\ the coordinate components of $x$.

  \begin{figure}[htbp]
    \centering

    \resizebox{0.9\textwidth}{!}{
      \input{1_basic_concepts/simplices.tex}
    }
    \caption{
      The simplices $S_1$, $S_2$, and $S_3$.
      For $S_1$, the standard simplex is the point $e_1$,
      for $S_2$, the standard simplex is the line segment between $e_1$ and $e_2$,
      and for $S_3$, the standard simplex is the triangle with vertices $e_1$, $e_2$, and $e_3$.\label{fig:simplices}
    }
  \end{figure}
\end{solution}

\begin{exercise}
  Show that each convex cone is indeed a convex set.
\end{exercise}

\begin{solution}
  To see that a convex cone is a convex set, let first $x_1,x_2 \in C$.
  Then let $0 \leq \lambda_1 \leq 1$ and $\lambda_2 = 1 - \lambda_1 \geq 0$.
  We then have by definition of the convex cone that
  \begin{equation}
    \lambda_1 x_1 + (1 - \lambda_1) x_1 = \lambda_1 x_1 + \lambda_2 x_2 \in C,
  \end{equation}
  showing that the set is convex.
\end{solution}

\begin{exercise}
  Let $A \in \mathbb{R}^{m \times n}$ and consider the set $C = \{ x \in \mathbb{R}^n : Ax \leq O \}$.
  Prove that $C$ is a convex cone.
\end{exercise}

\begin{solution}
  Let $x_1, x_2 \in C$ and $\lambda_1, \lambda_2 \in \mathbb{R}_+$.
  We then have
  \begin{equation}
    A(\lambda_1 x_1 + \lambda_2 x_2) = \lambda_1 Ax_1 + \lambda_2 Ax_2 \leq \lambda_1 O + \lambda_2 O = O,
  \end{equation}
  showing that the set is a convex cone.
\end{solution}

\paragraph{Polyhedral cone}
A convex cone of the form $\{x \in \mathbb{R}^n : Ax \leq O \}$ where $A \in \mathbb{R}^{m \times n}$ is called a \emph{polyhedral cone}.
Let $x_1, \ldots, x_t \in \mathbb{R}^n$ and let $C(x_1, \ldots, x_t)$ be the set of vectors of the form
\begin{equation}
  u = \sum_{j = 1}^{t} \lambda_j x_j,
\end{equation}
where $\lambda_j \geq 0$ for each $j = 1, \ldots, t$.

\begin{exercise}
  Prove that $C(x_1, \ldots, x_t)$ is a convex cone.
\end{exercise}

\begin{solution}
  Let $C = C(x_1, \ldots, x_t)$ here for convenience.
  Let $u, v \in C$ with respective coefficients $\lambda_j, \mu_j \geq 0$ for $j = 1, \ldots, t$.
  Then, for arbitrary coefficients $\alpha, \beta \geq 0$, we have
  \begin{equation}
    \begin{split}
      A(\alpha u + \beta v) &= A\left(\alpha \sum_{j=1}^{t} \lambda_j x_j + \beta \sum_{j=1}^{t} \mu_j x_j\right) \\
      &= \alpha A \sum_{j=1}^{t} \lambda_j x_j + \beta A \sum_{j=1}^{t} \mu_j x_j \\
      &\leq \alpha O + \beta O = O,
    \end{split}
  \end{equation}
  showing that $\alpha u + \beta v \in C$, and that $C$ is a convex cone.
\end{solution}

\begin{exercise}
  Let $S = \{ (x, y, z) : z \geq x^2 + y^2 \} \subset \mathbb{R}^3$.
  Sketch the set and verify that it is a convex set.
  Is $S$ a finitely generated cone?
\end{exercise}

\begin{solution}
  Let $u = (x_1, y_1, z_1)$ and $v = (x_2, y_2, z_2)$ be two points in $S$, and $0 \leq \lambda \leq 1$.
  We then seek to show that $\lambda u + (1 - \lambda) v \in S$.
  Note that $f(x) = x^2$ is convex, i.e.\ that $f(\lambda x_1 + (1 - \lambda) x_2) \leq \lambda f(x_1) + (1 - \lambda) f(x_2)$.

  Considering the right hand side of the inequality first, we have component-wise that
  \begin{equation}
    \begin{split}
      (\lambda x_1 + (1 - \lambda) x_2)^2 &\leq \lambda x_1^2 + (1 - \lambda) x_2^2 \\
      (\lambda y_1 + (1 - \lambda) y_2)^2 &\leq \lambda y_1^2 + (1 - \lambda) y_2^2,
    \end{split}
  \end{equation}
  and therefore
  \begin{equation}
    \begin{split}
      (\lambda x_1 + (1 - \lambda) x_2)^2 + (\lambda y_1 + (1 - \lambda) y_2)^2 &\leq \lambda (x_1^2 + y_1^2) + (1 - \lambda) (x_2^2 + y_2^2) \\
      &\leq \lambda z_1 + (1 - \lambda) z_2,
    \end{split}
  \end{equation}
  and so $\lambda u + (1 - \lambda) v \in S$, showing that $S$ is convex.

  $S$ is not a finitely generated cone, as it should then be closed under scaling.
  Consider e.g.\ $u = (1,0,1)$, which satisfies $1 \geq 1^2 + 0^2$ and so $u \in S$.
  Letting however $\lambda_1 = 2$ (and $\lambda_2 = 0$), we have $2u = (2,0,2) \notin S$ as $2 \not\geq 2^2 + 0^2$.
\end{solution}

\begin{exercise}
  Consider the linear system $0 \leq x_i \leq 1$ for $i = 1, \ldots, n$, and let $P$ denote the solution set.
  Explain how to solve a linear programming problem
  \begin{equation}
    \max\{ c^T x : x \in P \}.
  \end{equation}
  What if the linear system was $a_i \leq x_i \leq b_i$ for $i = 1, \ldots, n$?
  Here we assume $a_i \leq b_i$ for each $i$.
\end{exercise}

\begin{solution}
  We choose the solution component-wise, by maximizing each component $c_i x_i$.
  If $c_i > 0$, simply let $x_i = 1$.
  If $c_i < 0$, increasing $x_i$ decreases the objective function, so we let $x_i = 0$.
  The same argument holds in the alternate case, just choose $x_i = b_i$ or $x_i = a_i$ respectively based on the sign of $c_i$.
\end{solution}

\begin{exercise}
  Is the union of two convex sets again convex?
\end{exercise}

\begin{solution}
  No.
  Let $A = [-2, -1]$ and $B = [1, 2]$.
  Then $A \cup B = [-2, -1] \cup [1, 2]$ is not convex, as e.g.\ $\tfrac{1}{2} 1 + (1 - \tfrac{1}{2}) (-1) = 0 \notin A \cup B$.
\end{solution}

\begin{exercise}
  Determine the sum $A + B$ in each of the following cases:
  \begin{align*}
    (i) && A &= \{ (x, y) : x^2 + y^2 \leq 1 \}, & B &= \{ (3, 4) \}; \\
    (ii) && A &= \{ (x, y) : x^2 + y^2 \leq 1 \}, & B &= [0, 1] \times \{0\}; \\
    (iii) && A &= \{ (x, y) : x + 2y = 5 \}, & B &= \{ (x, y) : x = y, 0 \leq x \leq 1 \}; \\
    (iv) && A &= [0, 1] \times [1, 2], & B &= [0, 2] \times [0, 2].
  \end{align*}
\end{exercise}

\begin{solution}
  Taking the cases in turn:

  (\emph{i}) The sum $A + B$ is given by the set of points $\{ u + (3, 4) : u \in A \}$, that is, the unit disk centred around $(3, 4)$.

  (\emph{ii}) The sum $A + B$ is given by those points that are either in the rectangle with corners at $(0,-1)$, $(1, -1)$, $(1, 1)$ and $(0, 1)$, or in the unit disks centred about $(0,0)$ or $(1, 0)$.

  (\emph{iii}) Let $B = \{ (\lambda, \lambda) : 0 \leq \lambda \leq 1 \}$.
  Then we can write a point $(x, y) \in A + B$ as
  \begin{equation}
    (x, y) = (x_0 + \lambda, y_0 + \lambda).
  \end{equation}
  Then
  \begin{equation}
    x + 2y = (x_0 + 2y_0) + 3 \lambda = 5 + 3\lambda,
  \end{equation}
  which gives us that
  \begin{equation}
    A + B = \{ (x, y) : 5 \leq x + 2y \leq 8 \}.
  \end{equation}

  (\emph{iv}) The sum $A + B$ is simply given by $[0, 3] \times [1, 4]$.
\end{solution}

\begin{exercise}
  More enumerated exercises\dots

  \begin{enumerate}[label = (\emph{\roman*})]
    \item Prove that, for every $\lambda \in \mathbb{R}$ and $A, B \subseteq \mathbb{R}^n$, it holds that $\lambda(A + B) = \lambda A + \lambda B$.

    \item Is it true that $(\lambda + \mu) A = \lambda A + \mu A$ for every $\lambda, \mu \in \mathbb{R}$ and $A \subseteq \mathbb{R}^n$?
      If not, find a counterexample.

    \item Show that, if $\lambda, \mu \geq 0$ and $A \subseteq \mathbb{R}^n$ is convex, then $(\lambda + \mu) A = \lambda A + \mu A$.
  \end{enumerate}
\end{exercise}

\begin{solution}
  Taking the exercises in turn again\dots

  (\emph{i}) We have that
  \begin{align*}
    \lambda (A + B) &= \{ \lambda (a + b) : a \in A, b \in B \} \\
    &= \{ \lambda a + \lambda b : a \in A, b \in B \} \\
    &= \{ a + b : a \in \lambda A, b \in \lambda B \} \\
    &= \lambda A + \lambda B.
  \end{align*}

  (\emph{ii}) No, it is not true.
  Consider $A = [1, 2]$, $\lambda = 1$ and $\mu = -1$.
  Then we have
  \begin{equation}
    (\lambda + \mu) A = 0A = \{ 0 \}
    \quad\text{and}\quad
    \lambda A + \mu A = [1, 2] + [-2, -1] = [-1, 1].
  \end{equation}

  (\emph{iii}) Let $\lambda, \mu \geq 0$.
  For any $a \in A$, we have that
  \begin{equation}
    (\lambda + \mu) a = \lambda a + \mu a \in \lambda A + \mu A,
  \end{equation}
  so $(\lambda + \mu) A \subseteq \lambda A + \mu A$.
  For the reverse inclusion, let $u \in \lambda A + \mu A$.
  Then $u = \lambda a + \mu b$ for some $a, b \in A$.
  Scaling the factors, we have that
  \begin{equation}
    u = (\lambda + \mu) \left(
      \frac{\lambda}{\lambda + \mu} a + \frac{\mu}{\lambda + \mu} b
    \right).
  \end{equation}
  As both the inner coefficients are non-negative and sum to one, and $a, b \in A$, we have that
  \begin{equation}
    \frac{\lambda}{\lambda + \mu} a + \frac{\mu}{\lambda + \mu} b \in A,
  \end{equation}
  and $u \in (\lambda + \mu) A$.
  Therefore, $(\lambda + \mu) A = \lambda A + \mu A$ with the given assumptions.
\end{solution}

\begin{exercise}
  Show that if $C_1, \dots, C_t \subseteq \mathbb{R}^n$ are all convex sets, then $C_1 \cap \dots \cap C_t$ is convex.
  Do the same when all sets are affine (or linear subspaces, or convex cones).
  In fact, a similar result for the intersection of any family of convex sets.
  Explain this.
\end{exercise}